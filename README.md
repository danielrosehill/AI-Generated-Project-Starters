# AI Generated Project Starters!

![alt text](images/banner.jpg)

The purpose of this repository is to provide a small aggregation of starters for web development projects generated by artificial intelligence (AI). 

As the capabilities of AI tools to generate accurate code increase over time, hopefully the utility of these code snippets will too. 

The project starters are sometimes projects that I'm working on myself. In other instances, their ideas that I've parked for the moment for later evaluation.  

In some instances I record all the details for the start of the project, ie both the prompt that I've written as well as an LLM, improved prompt, and finally one or more outputs or code snippets from a model. In other instances I will just provide the prompt. which can be used for generation. Sometimes I might get round to sharing the outputs generated from it, other times I won't. 

I am deliberately including here both prompts that (at the time of writing), I know from expereience have a reasonably good chance of succeeding. With "success" being defined roughly as generating reasonably workable code on the first output or generating code that can achieve the desired functionalities with a reasonable amount of debugging and iteration.

In other instances, I am including prompts that I would put in the category of "moonshot prompts:" prompts that I know are asking completely unreasonable requests from an AI tool, at least with its current capabilities.  I love experimenting with the latter category of prompts because they provide a good way of testing out the capabilities of some of the state-of-the-art models.

Some light attempts at prompt engineering are made in some of the instructions. Given that elaborate code generation requests almost by nature necessitate lengthy outputs, some kind of chunking instruction is often required, and probably desirable whenever it's ommitted.

## Repository Structure
 
The repository is currently organized in the following fashion:

- Every project is organized into a folder describing the project. In the future, if I generate enough projects here, I might organize these individual project folders into categories, but for now, they're just at the root level.   
- Within every thematic folder, there is a prompt file, which contains the prompt which was used to generate the output.  
- Secondly, the project folders contain an output. The output is a copy and paste of the response returned from the LLM. Typically, I will use an instructional model, ideally one optimized for code generation, when using these prompts. At the time of writing, December 9th, 2024, I'm using Qwen 2.5 Coder accessed through Hugging Face. But in the future and for different reasons I might shift to different LLMs.

## Output Organisation

The mechanisms that make LLMs work also provide some innate variability in responses. While this is commonly thought of as a constraint for the code-generation use-case, it also enables little instances of creativity in the approaches that different models use.

If I collect more than one output for a specific code generation prompt, just as I do with the prompts, I will add them individually, whether through one aggregated outputs file or perhaps within a folder within the project folder.

Because these are code generation prompts, almost all of the outputs will contain scripts. Where possible I will save these as scripts within the project folders. If I don't get around to doing that, these grips should simply be embedded within the markdown files recording the outputs and should be easily extractable. 

In the doubly unlikely event that I get round to noting the scripts and more than one script is generated in a single output, I'll gather the scripts generated or code snippets into individual files within a script generated folder or something similar.

## Model Selection

Just as with trying different prompts with different refinement strategies, I'll sometimes take the same code generation prompt and try it out with different LLMs. 

Frequently the differences in response can be quite significant. Different LLMs might recommend completely different approaches for achieving the same aim.

At the time of setting up this repository (December 10th, 2024), my favorite LLMs for code generation are Qwen Coder 2.5 32B (which can be accessed for free via Hugging Face) and Deepseek Coder. However, at this relatively early stage in the exciting evolution of AII remain fairly unattached to anyone, vendor or model, and my usual strategy is to try out many of them with different parameter settings until I find one that does a reasonably good job at the use case I'm trying to execute on.

## Parameter Recording

Because the capabilities of large language models are so fast evolving, in addition to the prompts and outputs, wherever possible, I'll create a parameters file within the project folder in which I note the details such as the model used, and occasionally I'll also note the system instruction, as well as the temperature and top-P setting used. 

## Prompt Creation Process
 
 Sometimes, when writing prompts for code generation I go through several iterations.
 
 Frequently I will dictate the first prompt so it is quite open-ended and loose. 
 
 Then, I'll use an LLM to organize the prompt textually with the instruction that it should optimize the prompt for code generation in an LLM specifically. 
 
 In instances where both prompts are recorded - that is both the dictated prompt and the refined prompt - I'll include both (because sometimes the refined prompt is missing details or could be improved upon in its refinement.)

---

## Author

Daniel Rosehill  
(public at danielrosehill dot com)

## Licensing

This repository is licensed under CC-BY-4.0 (Attribution 4.0 International) 
[License](https://creativecommons.org/licenses/by/4.0/)

### Summary of the License
The Creative Commons Attribution 4.0 International (CC BY 4.0) license allows others to:
- **Share**: Copy and redistribute the material in any medium or format.
- **Adapt**: Remix, transform, and build upon the material for any purpose, even commercially.

The licensor cannot revoke these freedoms as long as you follow the license terms.

#### License Terms
- **Attribution**: You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.
- **No additional restrictions**: You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.

For the full legal code, please visit the [Creative Commons website](https://creativecommons.org/licenses/by/4.0/legalcode).